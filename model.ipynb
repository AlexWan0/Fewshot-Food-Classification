{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexwan/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 659/659 [00:00<00:00, 385kB/s]\n",
      "Using custom data configuration alexwan0--wikipedia-foods-f5f22c7a7d9ff903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/alexwan/.cache/huggingface/datasets/alexwan0___parquet/alexwan0--wikipedia-foods-f5f22c7a7d9ff903/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 429M/429M [00:08<00:00, 48.9MB/s]\n",
      "Downloading data: 100%|██████████| 423M/423M [00:08<00:00, 50.3MB/s]\n",
      "Downloading data: 100%|██████████| 418M/418M [00:07<00:00, 54.2MB/s]\n",
      "Downloading data: 100%|██████████| 414M/414M [00:07<00:00, 53.2MB/s]\n",
      "Downloading data: 100%|██████████| 398M/398M [00:07<00:00, 52.4MB/s]\n",
      "Downloading data: 100%|██████████| 399M/399M [00:07<00:00, 50.2MB/s]\n",
      "Downloading data: 100%|██████████| 353M/353M [00:06<00:00, 52.2MB/s]\n",
      "Downloading data: 100%|██████████| 466M/466M [00:11<00:00, 42.2MB/s]]\n",
      "Downloading data: 100%|██████████| 412M/412M [00:07<00:00, 51.7MB/s]\n",
      "Downloading data: 100%|██████████| 412M/412M [00:08<00:00, 48.5MB/s]\n",
      "Downloading data: 100%|██████████| 436M/436M [00:08<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████| 391M/391M [00:07<00:00, 50.2MB/s]\n",
      "Downloading data: 100%|██████████| 405M/405M [00:31<00:00, 13.0MB/s]\n",
      "Downloading data: 100%|██████████| 433M/433M [00:08<00:00, 52.7MB/s]\n",
      "Downloading data: 100%|██████████| 416M/416M [00:12<00:00, 32.8MB/s]\n",
      "Downloading data: 100%|██████████| 379M/379M [00:07<00:00, 50.5MB/s]\n",
      "Downloading data: 100%|██████████| 400M/400M [00:07<00:00, 54.2MB/s]\n",
      "Downloading data: 100%|██████████| 431M/431M [00:08<00:00, 49.9MB/s]\n",
      "Downloading data: 100%|██████████| 384M/384M [00:07<00:00, 52.1MB/s]\n",
      "Downloading data: 100%|██████████| 420M/420M [00:08<00:00, 52.2MB/s]\n",
      "Downloading data: 100%|██████████| 426M/426M [00:08<00:00, 51.7MB/s]\n",
      "Downloading data: 100%|██████████| 412M/412M [00:08<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████| 378M/378M [00:07<00:00, 49.8MB/s]\n",
      "Downloading data: 100%|██████████| 405M/405M [00:08<00:00, 47.5MB/s]\n",
      "Downloading data: 100%|██████████| 402M/402M [00:07<00:00, 53.4MB/s]\n",
      "Downloading data: 100%|██████████| 414M/414M [00:07<00:00, 55.9MB/s]\n",
      "Downloading data: 100%|██████████| 389M/389M [00:07<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████| 429M/429M [00:09<00:00, 47.1MB/s]\n",
      "Downloading data: 100%|██████████| 420M/420M [00:08<00:00, 51.6MB/s]\n",
      "Downloading data: 100%|██████████| 364M/364M [00:06<00:00, 52.8MB/s]\n",
      "Downloading data: 100%|██████████| 327M/327M [00:06<00:00, 53.2MB/s]\n",
      "Downloading data: 100%|██████████| 418M/418M [00:08<00:00, 46.8MB/s]\n",
      "Downloading data: 100%|██████████| 401M/401M [00:07<00:00, 53.8MB/s]\n",
      "Downloading data: 100%|██████████| 412M/412M [00:08<00:00, 46.8MB/s]\n",
      "Downloading data: 100%|██████████| 451M/451M [00:09<00:00, 48.2MB/s]\n",
      "Downloading data: 100%|██████████| 369M/369M [00:06<00:00, 56.1MB/s]\n",
      "Downloading data: 100%|██████████| 300M/300M [00:10<00:00, 28.7MB/s]\n",
      "Downloading data: 100%|██████████| 253M/253M [00:05<00:00, 46.1MB/s]\n",
      "Downloading data: 100%|██████████| 381M/381M [00:08<00:00, 43.7MB/s]\n",
      "Downloading data: 100%|██████████| 321M/321M [00:06<00:00, 47.7MB/s]\n",
      "Downloading data: 100%|██████████| 404M/404M [00:07<00:00, 50.6MB/s]\n",
      "Downloading data: 100%|██████████| 338M/338M [00:07<00:00, 47.6MB/s]\n",
      "Downloading data: 100%|██████████| 389M/389M [00:08<00:00, 48.0MB/s]\n",
      "Downloading data files: 100%|██████████| 2/2 [06:50<00:00, 205.27s/it]\n",
      "Computing checksums of downloaded files. They can be used for integrity verification. You can disable this by passing ignore_verifications=True to load_dataset\n",
      "Computing checksums: 100%|██████████| 43/43 [00:40<00:00,  1.06it/s]\n",
      "Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 162.27it/s]\n",
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/alexwan/.cache/huggingface/datasets/alexwan0___parquet/alexwan0--wikipedia-foods-f5f22c7a7d9ff903/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 96.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "#food_dataset = load_dataset('food101')\n",
    "#food_dataset = load_from_disk('dataset/test/dataset/')\n",
    "food_dataset = load_dataset('alexwan0/wikipedia-foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "label_index = {}\n",
    "\n",
    "for i, lbl in enumerate(food_dataset['train']['label']):\n",
    "    if lbl not in label_index:\n",
    "        label_index[lbl] = []\n",
    "    \n",
    "    # if len(label_index[lbl]) >= hash(lbl) % 10 + 1:\n",
    "        # continue\n",
    "    \n",
    "    label_index[lbl].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17570\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#with open('mapping.json') as f_in:\n",
    "with open('dataset/cuisine_by_country/label_mapping.json') as f_in:\n",
    "    name_to_index = json.load(f_in)\n",
    "\n",
    "index_to_name = {v: k for k, v in name_to_index.items()}\n",
    "\n",
    "num_classes = len(index_to_name)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59048\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import random\n",
    "\n",
    "label_index = {}\n",
    "\n",
    "for i, lbl in enumerate(food_dataset['train']['label']):\n",
    "    if lbl not in label_index:\n",
    "        label_index[lbl] = []\n",
    "    \n",
    "    # if len(label_index[lbl]) >= hash(lbl) % 10 + 1:\n",
    "        # continue\n",
    "    \n",
    "    label_index[lbl].append(i)\n",
    "\n",
    "fs_indices = list(chain(*label_index.values()))\n",
    "fs_subset = food_dataset['train'].select(fs_indices)\n",
    "\n",
    "print(len(fs_subset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from itertools import islice\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def label_to_string(label, template='A photo of a {name}. A picture of food.'):\n",
    "    label_name = index_to_name[label]\n",
    "    label_name = label_name.replace('_', ' ')\n",
    "    return template.format(name=label_name)\n",
    "\n",
    "def article_text_shorten(text, num_sentences=2):\n",
    "    sents = islice(nlp(text).sents, num_sentences)\n",
    "    sents = [str(s) for s in sents]\n",
    "    return ' '.join(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 4.52k/4.52k [00:00<00:00, 368kB/s]\n",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.71G/1.71G [00:07<00:00, 225MB/s]\n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 316/316 [00:00<00:00, 30.6kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 905/905 [00:00<00:00, 206kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 961k/961k [00:00<00:00, 3.97MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 2.93MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.22M/2.22M [00:00<00:00, 7.30MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 389/389 [00:00<00:00, 103kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "hidden_size = 768\n",
    "\n",
    "# laion/CLIP-ViT-H-14-laion2B-s32B-b79K\n",
    "# laion/CLIP-ViT-B-32-laion2B-s34B-b79K\n",
    "# openai/clip-vit-large-patch14\n",
    "def load_clip_model(device='cuda', model_name=\"openai/clip-vit-large-patch14\"):\n",
    "    model = CLIPModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "model, processor = load_clip_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CLIP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 126/59048 [00:40<5:19:16,  3.08it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m labels_all\u001b[39m.\u001b[39mappend(label)\n\u001b[1;32m     13\u001b[0m \u001b[39m#label_str = label_to_string(label)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m label_str \u001b[39m=\u001b[39m article_text_shorten(ex[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], num_sentences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     16\u001b[0m model_input \u001b[39m=\u001b[39m processor(\n\u001b[1;32m     17\u001b[0m     images\u001b[39m=\u001b[39mimage, text\u001b[39m=\u001b[39mlabel_str, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m model_output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_input)\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36marticle_text_shorten\u001b[0;34m(text, num_sentences)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39marticle_text_shorten\u001b[39m(text, num_sentences\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     sents \u001b[39m=\u001b[39m islice(nlp(text)\u001b[39m.\u001b[39msents, num_sentences)\n\u001b[1;32m     13\u001b[0m     sents \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sents]\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(sents)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:53\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:333\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/pipeline/_parser_internals/ner.pyx:272\u001b[0m, in \u001b[0;36mspacy.pipeline._parser_internals.ner.BiluoPushDown.set_annotations\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/tokens/doc.pyx:779\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/spacy/tokens/doc.pyx:105\u001b[0m, in \u001b[0;36mspacy.tokens.doc.SetEntsDefault.values\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/enum.py:443\u001b[0m, in \u001b[0;36mEnumMeta.__members__\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_names_)\n\u001b[0;32m--> 443\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__members__\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m    445\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    Returns a mapping of member name->value.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[39m    This mapping lists all enum members, including aliases. Note that this\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m    is a read-only view of the internal mapping.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m MappingProxyType(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_member_map_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "ref_images = torch.zeros((len(fs_subset), hidden_size))\n",
    "ref_text = torch.zeros((num_classes, hidden_size))\n",
    "labels_all = []\n",
    "\n",
    "for i, ex in enumerate(tqdm(fs_subset)):\n",
    "    image, label = ex['image'], ex['label']\n",
    "    labels_all.append(label)\n",
    "    \n",
    "    #label_str = label_to_string(label)\n",
    "    label_str = article_text_shorten(ex['text'], num_sentences=1)\n",
    "\n",
    "    model_input = processor(\n",
    "        images=image, text=label_str, return_tensors=\"pt\", padding=True, truncation=True\n",
    "    ).to('cuda')\n",
    "\n",
    "    model_output = model(**model_input)\n",
    "\n",
    "    ref_images[i] = model_output.image_embeds.detach().cpu()\n",
    "    ref_text[label] = model_output.text_embeds.detach().cpu()\n",
    "\n",
    "labels_oh = F.one_hot(torch.tensor(labels_all), num_classes=num_classes).float()\n",
    "labels_oh = labels_oh / torch.sum(labels_oh, dim=0, keepdim=True)\n",
    "assert not torch.isnan(labels_oh).any()\n",
    "\n",
    "with open('ref_text_article.pt', 'wb') as f_out:\n",
    "    torch.save(ref_text, f_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main TIP-Adapter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_single(test_image, beta=1.0, alpha=1.0):\n",
    "    test_image_embeds = model(\n",
    "        **(processor(images=test_image, text='', return_tensors=\"pt\", padding=True).to('cuda'))\n",
    "    ).image_embeds.cpu()\n",
    "\n",
    "    img_sim = torch.matmul(test_image_embeds, ref_images.T)\n",
    "    img_sim = ((-1) * (beta - beta * img_sim)).exp()\n",
    "    class_sim_img = torch.matmul(img_sim, labels_oh) # (1, num_classes)\n",
    "\n",
    "    class_sim_text = torch.matmul(test_image_embeds, ref_text.T) # (1, num_classes)\n",
    "\n",
    "    class_sim = alpha * class_sim_img + class_sim_text # (1, num_classes)\n",
    "\n",
    "    return class_sim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "food_dataset['validation'] = food_dataset['validation'].shuffle()\n",
    "\n",
    "def validate(alpha=1.0, beta=1.0, limit_test=500, verbose=False):\n",
    "    labels = []\n",
    "    preds = []\n",
    "    top_5_all = []\n",
    "\n",
    "    total_test = min(len(food_dataset['validation']), limit_test)\n",
    "\n",
    "    for test_idx, test_sample in enumerate(tqdm(food_dataset['validation'], total=total_test)):\n",
    "        if test_idx >= limit_test:\n",
    "            break\n",
    "        \n",
    "        test_label = test_sample['label']\n",
    "        test_image = test_sample['image']\n",
    "\n",
    "        logits = infer_single(test_image, alpha=alpha, beta=beta)\n",
    "        preds_top_5 = torch.sort(logits, descending=True)[1][0,:5]\n",
    "        preds_top_1 = preds_top_5[0]\n",
    "\n",
    "        labels.append(test_label)\n",
    "        preds.append(preds_top_1)\n",
    "        top_5_all.append(test_label in preds_top_5)\n",
    "\n",
    "    if verbose:\n",
    "        print(classification_report(labels, preds))\n",
    "\n",
    "    top_5_acc = sum(top_5_all) / len(top_5_all)\n",
    "\n",
    "    return accuracy_score(labels, preds), top_5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11684/11684 [26:27<00:00,  7.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5237932214994865, 0.6553406367682301)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(alpha=1, beta=5, limit_test=float('inf'), verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing {'alpha': 0.01, 'beta': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:10<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.13, 0.238) > best_score=-inf; best_config={'alpha': 0.01, 'beta': 0.01}\n",
      "testing {'alpha': 0.01, 'beta': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.132, 0.238) > best_score=0.13; best_config={'alpha': 0.01, 'beta': 0.1}\n",
      "testing {'alpha': 0.01, 'beta': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:08<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.138, 0.242) > best_score=0.132; best_config={'alpha': 0.01, 'beta': 1}\n",
      "testing {'alpha': 0.01, 'beta': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.144, 0.242) > best_score=0.138; best_config={'alpha': 0.01, 'beta': 2}\n",
      "testing {'alpha': 0.01, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:08<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.15, 0.25) > best_score=0.144; best_config={'alpha': 0.01, 'beta': 5}\n",
      "testing {'alpha': 0.1, 'beta': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:08<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.132, 0.238) <= best_score=0.15; best_config={'alpha': 0.01, 'beta': 5}\n",
      "testing {'alpha': 0.1, 'beta': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.14, 0.242) <= best_score=0.15; best_config={'alpha': 0.01, 'beta': 5}\n",
      "testing {'alpha': 0.1, 'beta': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.2, 0.3) > best_score=0.15; best_config={'alpha': 0.1, 'beta': 1}\n",
      "testing {'alpha': 0.1, 'beta': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.234, 0.34) > best_score=0.2; best_config={'alpha': 0.1, 'beta': 2}\n",
      "testing {'alpha': 0.1, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.272, 0.406) > best_score=0.234; best_config={'alpha': 0.1, 'beta': 5}\n",
      "testing {'alpha': 1, 'beta': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.14, 0.242) <= best_score=0.272; best_config={'alpha': 0.1, 'beta': 5}\n",
      "testing {'alpha': 1, 'beta': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.204, 0.312) <= best_score=0.272; best_config={'alpha': 0.1, 'beta': 5}\n",
      "testing {'alpha': 1, 'beta': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.392, 0.522) > best_score=0.272; best_config={'alpha': 1, 'beta': 1}\n",
      "testing {'alpha': 1, 'beta': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:07<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.438, 0.564) > best_score=0.392; best_config={'alpha': 1, 'beta': 2}\n",
      "testing {'alpha': 1, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.554, 0.654) > best_score=0.438; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 2, 'beta': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:05<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.152, 0.252) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 2, 'beta': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.254, 0.372) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 2, 'beta': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:05<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.412, 0.544) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 2, 'beta': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.45, 0.568) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 2, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.552, 0.648) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 5, 'beta': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.168, 0.27) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 5, 'beta': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:09<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.32, 0.48) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 5, 'beta': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.394, 0.534) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 5, 'beta': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.438, 0.552) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n",
      "testing {'alpha': 5, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_score=(0.548, 0.646) <= best_score=0.554; best_config={'alpha': 1, 'beta': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1, 2, 5],\n",
    "    'beta': [0.01, 0.1, 1, 2, 5]\n",
    "}\n",
    "\n",
    "best_hyps = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "for combination in itertools.product(*param_grid.values()):\n",
    "    hyps = dict(zip(param_grid.keys(), combination))\n",
    "    print(f'testing {hyps}')\n",
    "    score, top_5_score = validate(**hyps, limit_test=500)\n",
    "\n",
    "    if score > best_score:\n",
    "        print(f'new_score={score, top_5_score} > best_score={best_score}; best_config={hyps}')\n",
    "        best_hyps = hyps\n",
    "        best_score = score\n",
    "    else:\n",
    "        print(f'new_score={score, top_5_score} <= best_score={best_score}; best_config={best_hyps}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
